---
title: "Understood Take Home"
author: "Lawrence Love"
date: "February 13, 2019"
output:
  word_document: default
---
```{r}
dat=read.csv("TelcoCustomerChurn.csv", header=TRUE)
library(VIM)
library(randomForest)
library(tree)
```

For this case study, I chose to work with the term "customer retention". The search resulted in 2 datasets, both of which were datasets in the field of telecommunications, and both datasets were in relation to customer churn analysis. One dataset had more than double the amount of observations that the other had.

The dataset I chose is called "Telco Customer Churn", and I chose this dataset because I knew it would be a challenge for me. Customer retention is something I hadn't gotten the chance to experiment with in my schooling so I felt this dataset was perfect for testing myself. Another reason I chose the dataset is because I thought it would be interesting to compare my own habits to my findings.

There is an interesting problem to address here, and it's pretty straightforward: We have 21 variables making up our dataset that profile each customer, how can we use the variables to identify a pattern resulting in customer churning, and which variables are the strongest identifiers? Answering these questions helps to focus in on areas of interest to better understand ways of retaining customers.

I plan to solve the problem using Random Forests and Classification Trees. I will use a 75-25 training and testing data split. The response variable I'll be working with is "Churn" which is a binary variable with responses of "No" if the customer did not churn, and "Yes" if the customer did churn.

Set seed and create training and testing sets, check for missing values.
```{r}
set.seed(2019)
summary(aggr(dat, plot=FALSE))
dat1=na.omit(dat)
train = sample(1:nrow(dat1), 0.75*nrow(dat1))
dat.train = dat1[train,]
dat.test = dat1[-train,]
```
After checking for missing values we see that we have 11 observations with values missing for "TotalCharges". It is safe to assume that these values are simply missing at random, so we'll just remove these observations considering they only account for 0.16% of the data. 

On to the Random Forest.
```{r}
dat.rf=randomForest(Churn~.-customerID, mtry=6, importance=TRUE, dat.train)
dat.rf
```
We see that this model has an error rate of 21.33%. Next we'll view the model's ability to predict outcomes on the training set, followed by the testing set.

```{r}
train.rf.pred=predict(dat.rf, dat.train, type = "class")
table(train.rf.pred, dat.train$Churn)

test.rf.pred=predict(dat.rf, dat.test, type = "class")
table(test.rf.pred, dat.test$Churn)
```
We see that the training data is predicted extremely well with only 32 misclasssifcations out of 5274. However, this model is not doing a great job with the testing set when predicting that customers will churn.

Next we'll check importance.
```{r}
imp.df=as.data.frame(round(importance(dat.rf), digits=3))
imp.df[order(imp.df$MeanDecreaseAccuracy, decreasing = TRUE),]
varImpPlot(dat.rf, type=1)
```
We see from the plot that the 4 most important variables stand out in how important they are. Those variables are tenure, TotalCharges, Contract, and MonthlyCharges.

Let's use these four variablse in a Classification Tree.
```{r}
tree.dat=tree(Churn~tenure+TotalCharges+Contract+MonthlyCharges, dat.train)
summary(tree.dat)
plot(tree.dat)
text(tree.dat, pretty=0)
```
This tree plot is a bit confusing so to attempt to clean things up, we'll try fine tuning with cross validation and pruning.

```{r}
cv.dat=cv.tree(tree.dat, FUN=prune.misclass)
plot(cv.dat$size, cv.dat$dev, type="b")
```

Based on the plot we'll use a tree with 4 terminal nodes.
```{r}
prune.dat=prune.misclass(tree.dat, best=4)
plot(prune.dat)
text(prune.dat, pretty=0)
```

Let's see how well this tree can predict outcomes on the training set and testing set.
```{r}
train.cv.pred=predict(prune.dat, dat.train, type="class")
table(train.cv.pred, dat.train$Churn)

test.cv.pred=predict(prune.dat, dat.test, type="class")
table(test.cv.pred, dat.test$Churn)
```